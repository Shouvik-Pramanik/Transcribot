{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb96232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from jiwer) (8.1.5)\n",
      "Requirement already satisfied: rapidfuzz==2.13.7 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from jiwer) (2.13.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.12.6)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6817128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer\n",
    "from tensorflow.python.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6126b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_path = '/wavs/'\n",
    "metadata_path = 'metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a526bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ050-0274</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ050-0275</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ050-0276</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ050-0277</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ050-0278</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1  \\\n",
       "0      LJ001-0001  Printing, in the only sense with which we are ...   \n",
       "1      LJ001-0002                     in being comparatively modern.   \n",
       "2      LJ001-0003  For although the Chinese took impressions from...   \n",
       "3      LJ001-0004  produced the block books, which were the immed...   \n",
       "4      LJ001-0005  the invention of movable metal letters in the ...   \n",
       "...           ...                                                ...   \n",
       "13095  LJ050-0274  made certain recommendations which it believes...   \n",
       "13096  LJ050-0275  materially improve upon the procedures in effe...   \n",
       "13097  LJ050-0276  As has been pointed out, the Commission has no...   \n",
       "13098  LJ050-0277  with the active cooperation of the responsible...   \n",
       "13099  LJ050-0278  the recommendations we have here suggested wou...   \n",
       "\n",
       "                                                       2  \n",
       "0      Printing, in the only sense with which we are ...  \n",
       "1                         in being comparatively modern.  \n",
       "2      For although the Chinese took impressions from...  \n",
       "3      produced the block books, which were the immed...  \n",
       "4      the invention of movable metal letters in the ...  \n",
       "...                                                  ...  \n",
       "13095  made certain recommendations which it believes...  \n",
       "13096  materially improve upon the procedures in effe...  \n",
       "13097  As has been pointed out, the Commission has no...  \n",
       "13098  with the active cooperation of the responsible...  \n",
       "13099  the recommendations we have here suggested wou...  \n",
       "\n",
       "[13100 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header = None, quoting=3)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "799998e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ050-0274</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ050-0275</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ050-0276</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ050-0277</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ050-0278</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1  \\\n",
       "13095  LJ050-0274  made certain recommendations which it believes...   \n",
       "13096  LJ050-0275  materially improve upon the procedures in effe...   \n",
       "13097  LJ050-0276  As has been pointed out, the Commission has no...   \n",
       "13098  LJ050-0277  with the active cooperation of the responsible...   \n",
       "13099  LJ050-0278  the recommendations we have here suggested wou...   \n",
       "\n",
       "                                                       2  \n",
       "13095  made certain recommendations which it believes...  \n",
       "13096  materially improve upon the procedures in effe...  \n",
       "13097  As has been pointed out, the Commission has no...  \n",
       "13098  with the active cooperation of the responsible...  \n",
       "13099  the recommendations we have here suggested wou...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f9a9270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>normalized_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ050-0135</td>\n",
       "      <td>According to Secretary Dillon,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ008-0277</td>\n",
       "      <td>Convicted offenders might have good or bad luc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ015-0313</td>\n",
       "      <td>Saward spent all his share at low gaming house...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ019-0232</td>\n",
       "      <td>During this reconstruction the female prisoner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ049-0134</td>\n",
       "      <td>The Commission suggests that consideration mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ008-0292</td>\n",
       "      <td>but it was seldom less than six weeks. It all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ035-0202</td>\n",
       "      <td>Fingerprint and palmprint evidence establishes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ018-0117</td>\n",
       "      <td>Wagner, after conviction, offered to reveal, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ031-0204</td>\n",
       "      <td>with three Secret Service agents, accompanied ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ033-0210</td>\n",
       "      <td>told the curtain rod story to Frazier to expla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name                           normalized_transcription\n",
       "0      LJ050-0135                     According to Secretary Dillon,\n",
       "1      LJ008-0277  Convicted offenders might have good or bad luc...\n",
       "2      LJ015-0313  Saward spent all his share at low gaming house...\n",
       "3      LJ019-0232  During this reconstruction the female prisoner...\n",
       "4      LJ049-0134  The Commission suggests that consideration mig...\n",
       "...           ...                                                ...\n",
       "13095  LJ008-0292  but it was seldom less than six weeks. It all ...\n",
       "13096  LJ035-0202  Fingerprint and palmprint evidence establishes...\n",
       "13097  LJ018-0117  Wagner, after conviction, offered to reveal, f...\n",
       "13098  LJ031-0204  with three Secret Service agents, accompanied ...\n",
       "13099  LJ033-0210  told the curtain rod story to Frazier to expla...\n",
       "\n",
       "[13100 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
    "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
    "metadata_df = metadata_df.sample(frac=1).reset_index(drop = True)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e79f13",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eda11445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training dataset :-  11790\n",
      "Size of validation dataset :-  1310\n"
     ]
    }
   ],
   "source": [
    "split = int(len(metadata_df) * 0.90)\n",
    "df_train = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "print(\"Size of the training dataset :- \", len(df_train))\n",
    "print(\"Size of validation dataset :- \", len(df_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ae64d",
   "metadata": {},
   "source": [
    "### Mapping all the English characters to numbers for feeding into Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "faf21649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is :-  ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' ']\n",
      "The size is :-  31\n"
     ]
    }
   ],
   "source": [
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "nums_to_char = keras.layers.StringLookup(vocabulary = to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "print(\"The vocabulary is :- \", to_num.get_vocabulary())\n",
    "print(\"The size is :- \", to_num.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad150ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edfccaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_sample(wav_file, label) : \n",
    "    ### Step 1 :- Process the audio\n",
    "    file = tf.io.read_file(wavs_path + wav_file + '.wav')\n",
    "    #Converting wav file into float tensor\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    #Remove repetitive tensors and keep only multi-dimensional tensors\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    #Converting the tensors into into the datatype float32\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    spectrogram = tf.signal.stft(audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length)\n",
    "    #Getting the absolute value of spectrogram i.e the magitude\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    mean = tf.math.reduce_mean(spectrogram, 1, keepdims = True)\n",
    "    stddev = tf.math.reduce_std(spectrogram, 1, keepdims = True)\n",
    "    spectrogram = (spectrogram-mean)/(stddev+1e-10)\n",
    "    ### Step 2 :- Process the label\n",
    "    label = tf.strings.lower(label)\n",
    "    label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\")\n",
    "    label = to_num(label)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606295d",
   "metadata": {},
   "source": [
    "### Dividing the dataset into dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73400cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"]))\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"file_name\"]), list(df_val[\"normalized_transcription\"]))\n",
    ")\n",
    "\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ad703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e555ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred) : \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "    \n",
    "    input_length = input_length*tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    label_length = label_length*tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    \n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1fdf5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers = 5, rnn_units = 128) :\n",
    "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "    # 2 CNN Layers\n",
    "    x = layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = [11,41],\n",
    "        strides = [2, 2],\n",
    "        padding = \"same\",\n",
    "        use_bias = False,\n",
    "        name = \"conv_1\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name = \"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name = \"conv_1_relu\")(x)\n",
    "    x = layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = [11,21],\n",
    "        strides = [1,2],\n",
    "        padding = \"same\",\n",
    "        use_bias = False,\n",
    "        name = \"conv_2\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name = \"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name = \"conv_2_relu\")(x)\n",
    "    x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)\n",
    "    \n",
    "    # RNN Layers\n",
    "    for i in range(1, rnn_layers + 1) :\n",
    "        recurrent = layers.GRU(\n",
    "            units = rnn_units,\n",
    "            activation = \"tanh\",\n",
    "            recurrent_activation = 'sigmoid',\n",
    "            use_bias = True,\n",
    "            return_sequences = True,\n",
    "            reset_after = True,\n",
    "            name = f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name = f\"bidirectional_{i}\", merge_mode = \"concat\"\n",
    "        )(x)\n",
    "        if i<rnn_layers :\n",
    "            x = layers.Dropout(rate = 0.5)(x)\n",
    "    # Dense Layer\n",
    "    x = layers.Dense(units = rnn_units*2, name = \"dense_1\")(x)\n",
    "    x = layers.ReLU(name = \"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate = 0.5)(x)\n",
    "    # Classification Layer\n",
    "    output = layers.Dense(units = output_dim + 1, activation = \"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name = \"DeepSpeech_2\")\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    model.compile(optimizer = opt, loss = CTCLoss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "47fe8cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 193)]                         0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape_4 (Reshape)                             (None, None, 1568)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n",
      "                                                                                                              \n",
      " dropout_20 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_21 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_22 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_23 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dropout_24 (Dropout)                            (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dense_4 (Dense)                                 (None, None, 32)                            32800            \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 26,628,480\n",
      "Trainable params: 26,628,352\n",
      "Non-trainable params: 128\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_dim = fft_length // 2 + 1,\n",
    "    output_dim = to_num.vocabulary_size(),\n",
    "    rnn_units = 512\n",
    ")\n",
    "model.summary(line_length = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbb13eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred) :\n",
    "    input_len = np.ones(pred.shape[0])*pred_shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0]\n",
    "    output_text = []\n",
    "    for result in results :\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "class CallbackEval(keras.callbacks.Callback) :\n",
    "    \"\"\"Displays a batch of outputs after each epoch\"\"\"\n",
    "    def __init__(self,dataset) :\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "    def on_epoch_end(self, epoch: int, logs = None) :\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset :\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y :\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate : {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2) :\n",
    "            print(f\"Target      :{targets[i]}\")\n",
    "            print(f\"Predictions :{predictions[i]}\")\n",
    "            print(\"-\" * 100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4222ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nNewRandomAccessFile failed to Create/Open: /wavs/LJ050-0135.wav : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_69142]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26688\\3507111886.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalidation_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCallbackEval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nNewRandomAccessFile failed to Create/Open: /wavs/LJ050-0135.wav : The system cannot find the path specified.\r\n; No such process\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_69142]"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = validation_dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks = [validation_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1f831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d0601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
