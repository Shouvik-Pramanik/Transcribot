{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb96232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from jiwer) (8.1.5)\n",
      "Requirement already satisfied: rapidfuzz==2.13.7 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from jiwer) (2.13.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.5)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.28.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.12.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.51.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: keras in c:\\users\\shouvik\\anaconda3\\lib\\site-packages (2.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6817128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer\n",
    "from tensorflow.python.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6126b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link to the dataset - https://keithito.com/LJ-Speech-Dataset/\n",
    "wavs_path = 'dataset/wavs/'\n",
    "metadata_path = 'dataset/metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a526bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ050-0274</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ050-0275</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ050-0276</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ050-0277</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ050-0278</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1  \\\n",
       "0      LJ001-0001  Printing, in the only sense with which we are ...   \n",
       "1      LJ001-0002                     in being comparatively modern.   \n",
       "2      LJ001-0003  For although the Chinese took impressions from...   \n",
       "3      LJ001-0004  produced the block books, which were the immed...   \n",
       "4      LJ001-0005  the invention of movable metal letters in the ...   \n",
       "...           ...                                                ...   \n",
       "13095  LJ050-0274  made certain recommendations which it believes...   \n",
       "13096  LJ050-0275  materially improve upon the procedures in effe...   \n",
       "13097  LJ050-0276  As has been pointed out, the Commission has no...   \n",
       "13098  LJ050-0277  with the active cooperation of the responsible...   \n",
       "13099  LJ050-0278  the recommendations we have here suggested wou...   \n",
       "\n",
       "                                                       2  \n",
       "0      Printing, in the only sense with which we are ...  \n",
       "1                         in being comparatively modern.  \n",
       "2      For although the Chinese took impressions from...  \n",
       "3      produced the block books, which were the immed...  \n",
       "4      the invention of movable metal letters in the ...  \n",
       "...                                                  ...  \n",
       "13095  made certain recommendations which it believes...  \n",
       "13096  materially improve upon the procedures in effe...  \n",
       "13097  As has been pointed out, the Commission has no...  \n",
       "13098  with the active cooperation of the responsible...  \n",
       "13099  the recommendations we have here suggested wou...  \n",
       "\n",
       "[13100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header = None, quoting=3)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799998e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ050-0274</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "      <td>made certain recommendations which it believes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ050-0275</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "      <td>materially improve upon the procedures in effe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ050-0276</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "      <td>As has been pointed out, the Commission has no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ050-0277</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "      <td>with the active cooperation of the responsible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ050-0278</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "      <td>the recommendations we have here suggested wou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                                                  1  \\\n",
       "13095  LJ050-0274  made certain recommendations which it believes...   \n",
       "13096  LJ050-0275  materially improve upon the procedures in effe...   \n",
       "13097  LJ050-0276  As has been pointed out, the Commission has no...   \n",
       "13098  LJ050-0277  with the active cooperation of the responsible...   \n",
       "13099  LJ050-0278  the recommendations we have here suggested wou...   \n",
       "\n",
       "                                                       2  \n",
       "13095  made certain recommendations which it believes...  \n",
       "13096  materially improve upon the procedures in effe...  \n",
       "13097  As has been pointed out, the Commission has no...  \n",
       "13098  with the active cooperation of the responsible...  \n",
       "13099  the recommendations we have here suggested wou...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f9a9270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>normalized_transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ017-0244</td>\n",
       "      <td>The murders were perpetrated on the tenth Sept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ026-0083</td>\n",
       "      <td>Starch, however, contains potential energy, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ018-0345</td>\n",
       "      <td>As in that case, the grave had been dug long i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ004-0145</td>\n",
       "      <td>At Guildford prison, which Mr. Buxton also vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ018-0244</td>\n",
       "      <td>The effect of establishing the forgeries would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>LJ044-0179</td>\n",
       "      <td>He apparently based his claim for a visa in tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>LJ031-0089</td>\n",
       "      <td>considerable time which at this juncture was n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13097</th>\n",
       "      <td>LJ034-0119</td>\n",
       "      <td>Approximately seven or eight minutes later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13098</th>\n",
       "      <td>LJ021-0077</td>\n",
       "      <td>There is no magic formula,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13099</th>\n",
       "      <td>LJ036-0078</td>\n",
       "      <td>claimed that about fifteen minutes after the a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name                           normalized_transcription\n",
       "0      LJ017-0244  The murders were perpetrated on the tenth Sept...\n",
       "1      LJ026-0083  Starch, however, contains potential energy, si...\n",
       "2      LJ018-0345  As in that case, the grave had been dug long i...\n",
       "3      LJ004-0145  At Guildford prison, which Mr. Buxton also vis...\n",
       "4      LJ018-0244  The effect of establishing the forgeries would...\n",
       "...           ...                                                ...\n",
       "13095  LJ044-0179  He apparently based his claim for a visa in tr...\n",
       "13096  LJ031-0089  considerable time which at this juncture was n...\n",
       "13097  LJ034-0119         Approximately seven or eight minutes later\n",
       "13098  LJ021-0077                         There is no magic formula,\n",
       "13099  LJ036-0078  claimed that about fifteen minutes after the a...\n",
       "\n",
       "[13100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
    "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
    "metadata_df = metadata_df.sample(frac=1).reset_index(drop = True)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e79f13",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda11445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training dataset :-  9170\n",
      "Size of validation dataset :-  3930\n"
     ]
    }
   ],
   "source": [
    "split = int(len(metadata_df) * 0.70)\n",
    "df_train = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "print(\"Size of the training dataset :- \", len(df_train))\n",
    "print(\"Size of validation dataset :- \", len(df_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ae64d",
   "metadata": {},
   "source": [
    "### Mapping all the English characters to numbers for feeding into Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf21649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is :-  ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' ']\n",
      "The size is :-  31\n"
     ]
    }
   ],
   "source": [
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "nums_to_char = keras.layers.StringLookup(vocabulary = to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "print(\"The vocabulary is :- \", to_num.get_vocabulary())\n",
    "print(\"The size is :- \", to_num.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad150ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 256\n",
    "frame_step = 160\n",
    "fft_length = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edfccaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_single_sample(wav_file, label) : \n",
    "    ### Step 1 :- Process the audio\n",
    "    file = tf.io.read_file(wavs_path + wav_file + '.wav')\n",
    "    #Converting wav file into float tensor\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    #Remove repetitive tensors and keep only multi-dimensional tensors\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    #Converting the tensors into into the datatype float32\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    spectrogram = tf.signal.stft(audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length)\n",
    "    #Getting the absolute value of spectrogram i.e the magitude\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    mean = tf.math.reduce_mean(spectrogram, 1, keepdims = True)\n",
    "    stddev = tf.math.reduce_std(spectrogram, 1, keepdims = True)\n",
    "    spectrogram = (spectrogram-mean)/(stddev+1e-10)\n",
    "    ### Step 2 :- Process the label\n",
    "    label = tf.strings.lower(label)\n",
    "    label = tf.strings.unicode_split(label, input_encoding = \"UTF-8\")\n",
    "    label = to_num(label)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4606295d",
   "metadata": {},
   "source": [
    "### Dividing the dataset into dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73400cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"]))\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"file_name\"]), list(df_val[\"normalized_transcription\"]))\n",
    ")\n",
    "\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e555ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred) : \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "    \n",
    "    input_length = input_length*tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    label_length = label_length*tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "    \n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fdf5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers = 5, rnn_units = 128) :\n",
    "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "    # 2 CNN Layers\n",
    "    x = layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = [11,41],\n",
    "        strides = [2, 2],\n",
    "        padding = \"same\",\n",
    "        use_bias = False,\n",
    "        name = \"conv_1\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name = \"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name = \"conv_1_relu\")(x)\n",
    "    x = layers.Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = [11,21],\n",
    "        strides = [1,2],\n",
    "        padding = \"same\",\n",
    "        use_bias = False,\n",
    "        name = \"conv_2\"\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name = \"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name = \"conv_2_relu\")(x)\n",
    "    x = layers.Reshape((-1, x.shape[-2]*x.shape[-1]))(x)\n",
    "    \n",
    "    # RNN Layers\n",
    "    for i in range(1, rnn_layers + 1) :\n",
    "        recurrent = layers.GRU(\n",
    "            units = rnn_units,\n",
    "            activation = \"tanh\",\n",
    "            recurrent_activation = 'sigmoid',\n",
    "            use_bias = True,\n",
    "            return_sequences = True,\n",
    "            reset_after = True,\n",
    "            name = f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name = f\"bidirectional_{i}\", merge_mode = \"concat\"\n",
    "        )(x)\n",
    "        if i<rnn_layers :\n",
    "            x = layers.Dropout(rate = 0.5)(x)\n",
    "    # Dense Layer\n",
    "    x = layers.Dense(units = rnn_units*2, name = \"dense_1\")(x)\n",
    "    x = layers.ReLU(name = \"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate = 0.5)(x)\n",
    "    # Classification Layer\n",
    "    output = layers.Dense(units = output_dim + 1, activation = \"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name = \"DeepSpeech_2\")\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    model.compile(optimizer = opt, loss = CTCLoss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47fe8cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 193)]                         0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, None, 193, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 97, 32)                        14432            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 97, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 97, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 49, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 49, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 49, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape (Reshape)                               (None, None, 1568)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 1024)                          6395904          \n",
      "                                                                                                              \n",
      " dropout (Dropout)                               (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_1 (Dropout)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_2 (Dropout)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dropout_3 (Dropout)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 1024)                          4724736          \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 1024)                          1049600          \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dropout_4 (Dropout)                             (None, None, 1024)                          0                \n",
      "                                                                                                              \n",
      " dense (Dense)                                   (None, None, 32)                            32800            \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 26,628,480\n",
      "Trainable params: 26,628,352\n",
      "Non-trainable params: 128\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_dim = fft_length // 2 + 1,\n",
    "    output_dim = to_num.vocabulary_size(),\n",
    "    rnn_units = 512\n",
    ")\n",
    "model.summary(line_length = 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbb13eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred) :\n",
    "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
    "    results = keras.backend.ctc_decode(pred, input_length = input_len, greedy = True)[0][0]\n",
    "    output_text = []\n",
    "    for result in results :\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "class CallbackEval(keras.callbacks.Callback) :\n",
    "    \"\"\"Displays a batch of outputs after each epoch\"\"\"\n",
    "    def __init__(self,dataset) :\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "    def on_epoch_end(self, epoch: int, logs = None) :\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset :\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y :\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate : {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2) :\n",
    "            print(f\"Target      :{targets[i]}\")\n",
    "            print(f\"Predictions :{predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4222ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = validation_dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks = [validation_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "targets = []\n",
    "for batch in validation_dataset : \n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y :\n",
    "        label = (\n",
    "            tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        )\n",
    "        targets.append(label)\n",
    "wer_score = wer(targets, predictions)\n",
    "for i in np.random.randint(0, len(predictions), 5) :\n",
    "    print(f\"Target      :{targets[i]}\")\n",
    "    print(f\"Predictions :{predictions[i]}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c84b5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
